# app_combined_enhanced_with_VG_fitting.py - ç”Ÿç‰©ç‚­æ”¹æ€§åœŸSWCCé¢„æµ‹ç³»ç»Ÿï¼ˆå¢å¼ºç‰ˆï¼Œå¸¦VGæ¨¡å‹æ‹Ÿåˆï¼‰
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import io
import warnings
from scipy.optimize import curve_fit

warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“ï¼ˆæ”¾åœ¨å¯¼å…¥åç«‹å³è®¾ç½®ï¼‰
import matplotlib

matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'Microsoft YaHei']
matplotlib.rcParams['axes.unicode_minus'] = False

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç”Ÿç‰©ç‚­æ”¹æ€§åœŸSWCCé¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸŒ±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é¡µé¢æ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #2E8B57;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #3CB371;
        margin-top: 1.5rem;
        margin-bottom: 1rem;
    }
    .info-box {
        background-color: #f0f8ff;
        padding: 15px;
        border-radius: 10px;
        border-left: 5px solid #4682B4;
        margin: 10px 0;
    }
    .warning-box {
        background-color: #fffacd;
        padding: 15px;
        border-radius: 10px;
        border-left: 5px solid #FFD700;
        margin: 10px 0;
    }
    .success-box {
        background-color: #e6ffe6;
        padding: 15px;
        border-radius: 10px;
        border-left: 5px solid #32CD32;
        margin: 10px 0;
    }
    .stButton > button {
        background-color: #2E8B57;
        color: white;
        font-weight: bold;
        padding: 10px 24px;
        border-radius: 5px;
        border: none;
        transition: all 0.3s;
    }
    .stButton > button:hover {
        background-color: #3CB371;
        transform: scale(1.05);
    }
    .model-selector {
        background-color: #e8f4f8;
        padding: 15px;
        border-radius: 10px;
        border: 2px solid #87CEEB;
        margin-bottom: 20px;
    }
    .stNumberInput input {
        font-size: 14px;
    }
    .batch-results {
        max-height: 400px;
        overflow-y: auto;
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 10px;
        margin-top: 10px;
    }
    .parameter-table {
        background-color: #f8f9fa;
        border-radius: 8px;
        padding: 10px;
        margin: 10px 0;
        border: 1px solid #dee2e6;
    }
    .vg-equation {
        font-family: "Times New Roman", Times, serif;
        font-size: 1.2rem;
        text-align: center;
        background-color: #f0f0f0;
        padding: 10px;
        border-radius: 5px;
        margin: 10px 0;
        border: 1px solid #ccc;
    }
</style>
""", unsafe_allow_html=True)


# VGæ¨¡å‹å‡½æ•°å®šä¹‰
def vg_model(h, theta_r, theta_s, alpha, n):
    """
    van Genuchtenæ¨¡å‹
    Î¸ = Î¸r + (Î¸s - Î¸r) / [1 + (Î±Â·h)^n]^m
    å…¶ä¸­ m = 1 - 1/n
    """
    m = 1 - 1 / n
    return theta_r + (theta_s - theta_r) / ((1 + (alpha * h) ** n) ** m)


def fit_vg_model(suction_data, theta_data, initial_guess=None):
    """
    å¯¹SWCCæ•°æ®è¿›è¡ŒVGæ¨¡å‹æ‹Ÿåˆ

    å‚æ•°:
    - suction_data: å¸åŠ›æ•°æ®(kPa)
    - theta_data: å«æ°´ç‡æ•°æ®
    - initial_guess: åˆå§‹çŒœæµ‹å‚æ•° [Î¸r, Î¸s, Î±, n]

    è¿”å›:
    - popt: æœ€ä¼˜æ‹Ÿåˆå‚æ•°
    - pcov: å‚æ•°çš„åæ–¹å·®çŸ©é˜µ
    - r_squared: å†³å®šç³»æ•°RÂ²
    - fitted_theta: æ‹Ÿåˆå€¼
    """
    # é»˜è®¤åˆå§‹çŒœæµ‹
    if initial_guess is None:
        # Î¸r: æœ€å°å«æ°´ç‡çš„90%
        # Î¸s: æœ€å¤§å«æ°´ç‡çš„110%
        # Î±: 1/ä¸­å€¼å¸åŠ›
        # n: å…¸å‹å€¼1.5
        theta_min = np.min(theta_data)
        theta_max = np.max(theta_data)
        suction_median = np.median(suction_data[suction_data > 0])

        initial_guess = [
            max(0, theta_min * 0.9),  # Î¸r
            min(0.5, theta_max * 1.1),  # Î¸s
            1.0 / suction_median if suction_median > 0 else 0.01,  # Î±
            1.5  # n
        ]

    # å‚æ•°è¾¹ç•Œæ¡ä»¶
    lower_bounds = [0, 0, 0.00001, 1.01]  # nå¿…é¡»å¤§äº1
    upper_bounds = [0.5, 0.6, 10, 10]  # åˆç†èŒƒå›´

    try:
        # ä½¿ç”¨curve_fitè¿›è¡Œæ‹Ÿåˆ
        popt, pcov = curve_fit(
            vg_model,
            suction_data,
            theta_data,
            p0=initial_guess,
            bounds=(lower_bounds, upper_bounds),
            maxfev=5000
        )

        # è®¡ç®—æ‹Ÿåˆå€¼
        fitted_theta = vg_model(suction_data, *popt)

        # è®¡ç®—RÂ²
        residuals = theta_data - fitted_theta
        ss_res = np.sum(residuals ** 2)
        ss_tot = np.sum((theta_data - np.mean(theta_data)) ** 2)
        r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0

        return popt, pcov, r_squared, fitted_theta

    except Exception as e:
        st.warning(f"VGæ¨¡å‹æ‹Ÿåˆå¤±è´¥: {e}")
        return None, None, 0, None


def plot_swcc_with_vg_fit(suction_range, predictions, vg_params=None, current_point=None):
    """ç»˜åˆ¶SWCCæ›²çº¿å’ŒVGæ¨¡å‹æ‹Ÿåˆç»“æœ"""
    # åˆ›å»ºå›¾å½¢
    fig, ax = plt.subplots(figsize=(10, 6))

    # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'Microsoft YaHei']
    plt.rcParams['axes.unicode_minus'] = False

    # ä¸»å›¾ï¼šSWCCæ›²çº¿
    ax.plot(suction_range, predictions, 'b-', linewidth=2, label='SWCC (XGBoost)')

    # å¦‚æœæä¾›äº†VGæ‹Ÿåˆå‚æ•°ï¼Œç»˜åˆ¶æ‹Ÿåˆæ›²çº¿
    if vg_params is not None:
        theta_r, theta_s, alpha, n = vg_params
        m = 1 - 1 / n
        fitted_curve = vg_model(suction_range, theta_r, theta_s, alpha, n)
        ax.plot(suction_range, fitted_curve, 'r--', linewidth=2, label=' vG model fitting curve')

        # åœ¨å›¾ä¸­æ·»åŠ VGæ–¹ç¨‹
        vg_eq = r'$\theta = \theta_r + \frac{\theta_s - \theta_r}{[1 + (\alpha h)^n]^m}$'
        ax.text(0.02, 0.98, vg_eq, transform=ax.transAxes, fontsize=12,
                verticalalignment='top', bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))

    # å¦‚æœæä¾›äº†å½“å‰ç‚¹ï¼Œåœ¨å›¾ä¸Šæ ‡å‡º
    if current_point:
        ax.plot(current_point[0], current_point[1], 'ro', markersize=10, label='Current prediction point')
        ax.annotate(f'({current_point[0]:.1f} kPa, {current_point[1]:.3f})',
                    xy=current_point,
                    xytext=(current_point[0] * 1.5, current_point[1] * 0.9),
                    arrowprops=dict(arrowstyle='->', color='red'),
                    fontsize=10, color='red')

    # è®¾ç½®ä¸»å›¾åæ ‡è½´
    ax.set_xscale('log')
    ax.set_xlabel('Suction (kPa)', fontsize=12)
    ax.set_ylabel('Volumetric water content', fontsize=12)
    ax.set_title(' SWCC and the VG model fitting curve', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.legend(loc='best', fontsize=10)
    ax.set_facecolor('#f8f9fa')

    # è®¾ç½®åæ ‡è½´èŒƒå›´
    ax.set_xlim(min(suction_range), max(suction_range))
    y_min = max(0, min(predictions) - 0.05)
    y_max = min(1, max(predictions) + 0.05)
    ax.set_ylim(y_min, y_max)

    # å¸åŠ›èŒƒå›´æ ‡è®°
    ax.text(0.02, 0.02, f'Suction range: {min(suction_range):.2f} - {max(suction_range):.0f} kPa',
            transform=ax.transAxes, fontsize=9,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.7))

    plt.tight_layout()
    return fig


def display_vg_parameters(popt, r_squared, suction_range, theta_data):
    """æ˜¾ç¤ºVGæ¨¡å‹å‚æ•°"""
    if popt is None:
        st.warning("VGæ¨¡å‹æ‹Ÿåˆå¤±è´¥ï¼Œæ— æ³•æ˜¾ç¤ºå‚æ•°")
        return

    theta_r, theta_s, alpha, n = popt
    m = 1 - 1 / n

    # åˆ›å»ºå‚æ•°è¡¨æ ¼
    st.markdown('<div class="sub-header">ğŸ“Š VGæ¨¡å‹æ‹Ÿåˆå‚æ•°</div>', unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown('<div class="parameter-table">', unsafe_allow_html=True)
        st.markdown("##### æ¨¡å‹å‚æ•°")

        param_data = {
            'å‚æ•°': ['Î¸r (æ®‹ä½™å«æ°´ç‡)', 'Î¸s (é¥±å’Œå«æ°´ç‡)', 'Î± (å€’æ•°çš„å¸åŠ›)', 'n (å½¢çŠ¶å‚æ•°)', 'm (=1-1/n)',
                     'RÂ² (å†³å®šç³»æ•°)'],
            'å€¼': [
                f"{theta_r:.6f}",
                f"{theta_s:.6f}",
                f"{alpha:.6f}",
                f"{n:.6f}",
                f"{m:.6f}",
                f"{r_squared:.6f}"
            ],
            'ç‰©ç†æ„ä¹‰': [
                'é«˜å¸åŠ›ä¸‹çš„æœ€å°å«æ°´ç‡',
                'é›¶å¸åŠ›ä¸‹çš„æœ€å¤§å«æ°´ç‡',
                'è¿›æ°”å€¼çš„å€’æ•°',
                'å­”å¾„åˆ†å¸ƒæŒ‡æ•°',
                'æ›²çº¿å½¢çŠ¶å‚æ•°',
                'æ‹Ÿåˆä¼˜åº¦ (1ä¸ºå®Œç¾æ‹Ÿåˆ)'
            ]
        }

        param_df = pd.DataFrame(param_data)
        st.dataframe(param_df, use_container_width=True, hide_index=True)
        st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        st.markdown('<div class="parameter-table">', unsafe_allow_html=True)
        st.markdown("##### ç‰¹å¾å¸åŠ›å€¼")

        # è®¡ç®—ç‰¹å¾å¸åŠ›
        # è¿›æ°”å€¼ (air entry value)
        ha = 1 / alpha if alpha > 0 else 0

        # æœ‰æ•ˆé¥±å’Œåº¦ä¸º0.5æ—¶çš„å¸åŠ›
        se = 0.5
        h50 = (1 / alpha) * ((1 / se ** (1 / m)) - 1) ** (1 / n) if alpha > 0 and m > 0 and n > 0 else 0

        feature_data = {
            'ç‰¹å¾ç‚¹': ['è¿›æ°”å€¼ ha', 'Se=0.5æ—¶å¸åŠ› hâ‚…â‚€', 'é¢„æµ‹æœ€å°å¸åŠ›', 'é¢„æµ‹æœ€å¤§å¸åŠ›', 'æ•°æ®ç‚¹æ•°é‡'],
            'å¸åŠ›å€¼ (kPa)': [
                f"{ha:.3f}",
                f"{h50:.3f}",
                f"{np.min(suction_range):.3f}",
                f"{np.max(suction_range):.3f}",
                f"{len(suction_range)}"
            ],
            'å¤‡æ³¨': [
                '1/Î±',
                'Se = (Î¸-Î¸r)/(Î¸s-Î¸r) = 0.5',
                'æ›²çº¿èµ·ç‚¹',
                'æ›²çº¿ç»ˆç‚¹',
                'SWCCæ›²çº¿ç‚¹æ•°'
            ]
        }

        feature_df = pd.DataFrame(feature_data)
        st.dataframe(feature_df, use_container_width=True, hide_index=True)
        st.markdown('</div>', unsafe_allow_html=True)

    # æ˜¾ç¤ºVGæ¨¡å‹æ–¹ç¨‹
    st.markdown('<div class="vg-equation">', unsafe_allow_html=True)
    st.markdown("### van Genuchten (VG) æ¨¡å‹æ–¹ç¨‹")
    st.latex(r'''
    \theta(h) = \theta_r + \frac{\theta_s - \theta_r}{\left[1 + (\alpha \cdot h)^n\right]^m}
    ''')
    st.markdown(f'''
    å…¶ä¸­:
    - Î¸(h): å¸åŠ›ä¸º h æ—¶çš„ä½“ç§¯å«æ°´ç‡
    - Î¸r = {theta_r:.4f} (æ®‹ä½™å«æ°´ç‡)
    - Î¸s = {theta_s:.4f} (é¥±å’Œå«æ°´ç‡)
    - Î± = {alpha:.6f} kPaâ»Â¹
    - n = {n:.4f}
    - m = 1 - 1/n = {m:.4f}
    ''')
    st.markdown('</div>', unsafe_allow_html=True)

    # æä¾›å‚æ•°ä¸‹è½½
    vg_params_dict = {
        'theta_r': theta_r,
        'theta_s': theta_s,
        'alpha': alpha,
        'n': n,
        'm': m,
        'R_squared': r_squared,
        'ha': ha,
        'h50': h50
    }

    vg_params_df = pd.DataFrame([vg_params_dict])

    csv_params = vg_params_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½VGæ¨¡å‹å‚æ•°",
        data=csv_params,
        file_name=f"VG_model_parameters_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
        use_container_width=True
    )


# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_models():
    """åŠ è½½ä¸¤ä¸ªè®­ç»ƒå¥½çš„XGBoostæ¨¡å‹"""
    models = {}

    try:
        # åŠ è½½å˜é‡ç»„ä¸€æ¨¡å‹ï¼ˆå«ç”Ÿç‰©ç‚­ç±»å‹å’Œçƒ­è§£æ¸©åº¦ï¼‰
        with open('xgboost_optimized_results/model_group1.pkl', 'rb') as f:
            models['group1'] = pickle.load(f)
        st.sidebar.success("âœ… å˜é‡ç»„ä¸€æ¨¡å‹åŠ è½½æˆåŠŸï¼")

        # è°ƒè¯•ï¼šæ˜¾ç¤ºæ¨¡å‹çš„ç‰¹å¾åç§°
        if hasattr(models['group1'], 'feature_names_in_'):
            st.sidebar.info(f"æ¨¡å‹æœŸæœ›çš„ç‰¹å¾: {list(models['group1'].feature_names_in_)}")
        else:
            st.sidebar.info("âš ï¸ æ¨¡å‹æ²¡æœ‰å­˜å‚¨ç‰¹å¾åç§°ä¿¡æ¯")

    except FileNotFoundError:
        st.sidebar.warning("âš ï¸ å˜é‡ç»„ä¸€æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹")
    except Exception as e:
        st.sidebar.warning(f"âš ï¸ å˜é‡ç»„ä¸€æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    try:
        # åŠ è½½å˜é‡ç»„äºŒæ¨¡å‹ï¼ˆå«ç”Ÿç‰©ç‚­ç†åŒ–æŒ‡æ ‡ï¼‰
        with open('xgboost_optimized_results/model_group2.pkl', 'rb') as f:
            models['group2'] = pickle.load(f)
        st.sidebar.success("âœ… å˜é‡ç»„äºŒæ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except FileNotFoundError:
        st.sidebar.warning("âš ï¸ å˜é‡ç»„äºŒæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°")
    except Exception as e:
        st.sidebar.warning(f"âš ï¸ å˜é‡ç»„äºŒæ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    return models


# åŠ è½½ç‰¹å¾ä¿¡æ¯
@st.cache_resource
def load_feature_info():
    """åŠ è½½ç‰¹å¾ä¿¡æ¯æ–‡ä»¶"""
    try:
        import json
        with open('xgboost_optimized_results/feature_info.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤å€¼
        return {
            'group1': {
                'feature_names': ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'temperature',
                                  'Biochar_type_combined'],
                'feature_order': ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'temperature',
                                  'Biochar_type_combined'],
                'biochar_categories': ["å†œä¸šåºŸå¼ƒç‰©", "æ—ä¸šæ®‹ä½™ç‰©", "ç•œç¦½ç²ªä¾¿", "åŸå¸‚æ±¡æ³¥", "å…¶ä»–"]
            },
            'group2': {
                'feature_names': ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'pH', 'AT', 'CT'],
                'feature_order': ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'pH', 'AT', 'CT']
            }
        }


def generate_swcc_curve(model, model_type, base_input, suction_range):
    """ç”ŸæˆSWCCæ›²çº¿æ•°æ®"""
    predictions = []

    for suction in suction_range:
        # å¤åˆ¶åŸºç¡€è¾“å…¥æ•°æ®
        input_data = base_input.copy()
        input_data['suction'] = suction

        # åˆ›å»ºç‰¹å¾DataFrame
        if model_type == 'group1':
            # å˜é‡ç»„ä¸€ï¼šä½¿ç”¨åˆ†ç±»ç‰¹å¾
            feature_order = ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'temperature', 'Biochar_type_combined']
            biochar_categories = ["å†œä¸šåºŸå¼ƒç‰©", "æ—ä¸šæ®‹ä½™ç‰©", "ç•œç¦½ç²ªä¾¿", "åŸå¸‚æ±¡æ³¥", "å…¶ä»–"]

            features_df = pd.DataFrame([input_data])
            features_df['Biochar_type_combined'] = pd.Categorical(
                features_df['Biochar_type_combined'],
                categories=biochar_categories
            )
            features_df = features_df[feature_order]
        else:
            # å˜é‡ç»„äºŒï¼šç›´æ¥ä½¿ç”¨åŸå§‹å€¼
            feature_order = ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'pH', 'AT', 'CT']
            features_df = pd.DataFrame([input_data])[feature_order]

        # è¿›è¡Œé¢„æµ‹
        prediction = model.predict(features_df)[0]
        predictions.append(prediction)

    return predictions


def batch_predict_group1(model, data_df, feature_info):
    """æ‰¹é‡é¢„æµ‹ - å˜é‡ç»„ä¸€"""
    predictions = []

    # è·å–ç‰¹å¾ä¿¡æ¯å’Œç±»åˆ«
    biochar_categories = feature_info.get('biochar_categories',
                                          ["å†œä¸šåºŸå¼ƒç‰©", "æ—ä¸šæ®‹ä½™ç‰©", "ç•œç¦½ç²ªä¾¿", "åŸå¸‚æ±¡æ³¥", "å…¶ä»–"])

    for idx, row in data_df.iterrows():
        try:
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = {
                'suction': float(row.get('suction', 0)),
                'clay': float(row.get('clay', 0)),
                'silt': float(row.get('silt', 0)),
                'sand': float(row.get('sand', 0)),
                'dd': float(row.get('dd', 0)),
                'BC': float(row.get('BC', 0)) / 100.0,  # è½¬æ¢ä¸ºå°æ•°
                'temperature': float(row.get('temperature', 0)),
                'Biochar_type_combined': str(row.get('Biochar_type_combined', 'å†œä¸šåºŸå¼ƒç‰©'))
            }

            # å½“BC=0æ—¶ï¼Œè°ƒæ•´å‚æ•°
            if input_data['BC'] == 0:
                input_data['temperature'] = 0.0
                input_data['Biochar_type_combined'] = 'å†œä¸šåºŸå¼ƒç‰©'  # é»˜è®¤å€¼

            # åˆ›å»ºDataFrame
            features_df = pd.DataFrame([input_data])
            features_df['Biochar_type_combined'] = pd.Categorical(
                features_df['Biochar_type_combined'],
                categories=biochar_categories
            )

            # æŒ‰ç…§ç‰¹å¾é¡ºåºæ’åˆ—
            feature_order = ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'temperature', 'Biochar_type_combined']
            features_df = features_df[feature_order]

            # è¿›è¡Œé¢„æµ‹
            prediction = model.predict(features_df)[0]
            predictions.append(prediction)

        except Exception as e:
            st.warning(f"ç¬¬ {idx + 1} è¡Œæ•°æ®é¢„æµ‹å¤±è´¥: {e}")
            predictions.append(np.nan)

    return predictions


def batch_predict_group2(model, data_df, feature_info):
    """æ‰¹é‡é¢„æµ‹ - å˜é‡ç»„äºŒ"""
    predictions = []

    for idx, row in data_df.iterrows():
        try:
            # å‡†å¤‡è¾“å…¥æ•°æ®
            bc = float(row.get('BC', 0)) / 100.0  # è½¬æ¢ä¸ºå°æ•°

            # å¤„ç†BC=0çš„æƒ…å†µ
            if bc == 0:
                ph = 0.0
                at = 0.0
                ct = 0.0
            else:
                ph = float(row.get('pH', 8.0))
                at = float(row.get('AT', 25.0))
                ct = float(row.get('CT', 60.0))

            # åˆ›å»ºç‰¹å¾åˆ—è¡¨
            features = [
                float(row.get('suction', 100.0)),
                float(row.get('clay', 0.2)),
                float(row.get('silt', 0.25)),
                float(row.get('sand', 0.55)),
                float(row.get('dd', 1.45)),
                bc,  # å°æ•°å½¢å¼
                ph,
                at,  # ç™¾åˆ†æ•°å½¢å¼
                ct  # ç™¾åˆ†æ•°å½¢å¼
            ]

            # åˆ›å»ºDataFrame
            feature_order = ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'pH', 'AT', 'CT']
            features_df = pd.DataFrame([features], columns=feature_order)

            # è¿›è¡Œé¢„æµ‹
            prediction = model.predict(features_df)[0]
            predictions.append(prediction)

        except Exception as e:
            st.warning(f"ç¬¬ {idx + 1} è¡Œæ•°æ®é¢„æµ‹å¤±è´¥: {e}")
            predictions.append(np.nan)

    return predictions


def validate_batch_data(data_df, model_type, feature_info):
    """éªŒè¯æ‰¹é‡æ•°æ®"""
    errors = []

    if model_type == 'group1':
        required_columns = ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'temperature', 'Biochar_type_combined']
        biochar_categories = feature_info.get('biochar_categories',
                                              ["å†œä¸šåºŸå¼ƒç‰©", "æ—ä¸šæ®‹ä½™ç‰©", "ç•œç¦½ç²ªä¾¿", "åŸå¸‚æ±¡æ³¥", "å…¶ä»–"])
    else:
        required_columns = ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'pH', 'AT', 'CT']

    # æ£€æŸ¥å¿…éœ€åˆ—
    missing_columns = [col for col in required_columns if col not in data_df.columns]
    if missing_columns:
        errors.append(f"ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(missing_columns)}")

    # æ£€æŸ¥æ•°æ®ç±»å‹
    for col in required_columns:
        if col in data_df.columns:
            # å°è¯•è½¬æ¢ä¸ºæ•°å€¼å‹ï¼ˆé™¤ç”Ÿç‰©ç‚­ç±»å‹å¤–ï¼‰
            if col != 'Biochar_type_combined':
                try:
                    data_df[col] = pd.to_numeric(data_df[col])
                except:
                    errors.append(f"åˆ— '{col}' åŒ…å«éæ•°å€¼æ•°æ®")

    # æ£€æŸ¥ç”Ÿç‰©ç‚­ç±»å‹æ˜¯å¦æœ‰æ•ˆ
    if model_type == 'group1' and 'Biochar_type_combined' in data_df.columns:
        invalid_types = data_df[~data_df['Biochar_type_combined'].isin(biochar_categories)][
            'Biochar_type_combined'].unique()
        if len(invalid_types) > 0:
            errors.append(f"æ— æ•ˆçš„ç”Ÿç‰©ç‚­ç±»å‹: {', '.join(invalid_types)}")

    # æ£€æŸ¥åœŸå£¤é¢—ç²’ç»„æˆä¹‹å’Œ
    if all(col in data_df.columns for col in ['clay', 'silt', 'sand']):
        data_df['total_particles'] = data_df['clay'] + data_df['silt'] + data_df['sand']
        invalid_rows = data_df[(data_df['total_particles'] > 1.0) | (data_df['total_particles'] < 0)].index.tolist()
        if invalid_rows:
            errors.append(f"è¡Œ {[i + 1 for i in invalid_rows]} çš„åœŸå£¤é¢—ç²’ç»„æˆä¹‹å’Œä¸åœ¨0-1èŒƒå›´å†…")

    return errors


def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    # åº”ç”¨æ ‡é¢˜
    st.markdown('<div class="main-header">ğŸŒ± ç”Ÿç‰©ç‚­æ”¹æ€§åœŸæŒæ°´ç‰¹å¾æ›²çº¿(SWCC)é¢„æµ‹ç³»ç»Ÿ</div>', unsafe_allow_html=True)

    # åŠ è½½æ¨¡å‹å’Œç‰¹å¾ä¿¡æ¯
    models = load_models()
    feature_info = load_feature_info()

    if not models:
        st.error("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")
        return

    # ä¾§è¾¹æ  - æ¨¡å‹é€‰æ‹©å’Œç³»ç»Ÿä¿¡æ¯
    with st.sidebar:
        st.title("ğŸ”§ ç³»ç»Ÿè®¾ç½®")

        # é¢„æµ‹æ¨¡å¼é€‰æ‹©
        st.markdown("### ğŸ“Š é€‰æ‹©é¢„æµ‹æ¨¡å¼")
        prediction_mode = st.radio(
            "é€‰æ‹©é¢„æµ‹æ¨¡å¼",
            ["å•ç‚¹é¢„æµ‹", "æ‰¹é‡é¢„æµ‹"],
            index=0
        )

        # æ¨¡å‹é€‰æ‹©
        st.markdown("### ğŸ¤– é€‰æ‹©é¢„æµ‹æ¨¡å‹")
        model_options = []
        if 'group1' in models:
            model_options.append("å˜é‡ç»„ä¸€ï¼šå«ç”Ÿç‰©ç‚­ç±»å‹å’Œçƒ­è§£æ¸©åº¦")
        if 'group2' in models:
            model_options.append("å˜é‡ç»„äºŒï¼šå«ç”Ÿç‰©ç‚­ç†åŒ–æŒ‡æ ‡")

        if not model_options:
            st.error("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            st.stop()

        selected_model = st.radio(
            "é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹",
            model_options,
            index=0
        )

        # ç¡®å®šæ¨¡å‹ç±»å‹
        if "å˜é‡ç»„ä¸€" in selected_model:
            model_type = 'group1'
            model_info = feature_info.get('group1', {})
            st.info("ä½¿ç”¨å˜é‡ç»„ä¸€ï¼šåŒ…å«ç”Ÿç‰©ç‚­ç±»å‹å’Œçƒ­è§£æ¸©åº¦")
        else:
            model_type = 'group2'
            model_info = feature_info.get('group2', {})
            st.info("ä½¿ç”¨å˜é‡ç»„äºŒï¼šåŒ…å«ç”Ÿç‰©ç‚­ç†åŒ–æŒ‡æ ‡(pH, AT, CT)")

        st.divider()

        # SWCCæ›²çº¿è®¾ç½®ï¼ˆä»…å•ç‚¹é¢„æµ‹æ—¶æ˜¾ç¤ºï¼‰
        if prediction_mode == "å•ç‚¹é¢„æµ‹":
            st.markdown("### ğŸ“ˆ SWCCæ›²çº¿è®¾ç½®")

            # VGæ¨¡å‹æ‹Ÿåˆé€‰é¡¹
            st.markdown("#### ğŸ”§ VGæ¨¡å‹æ‹Ÿåˆé€‰é¡¹")
            enable_vg_fitting = st.checkbox("å¯ç”¨VGæ¨¡å‹æ‹Ÿåˆ", value=True,
                                            help="å¯¹ç”Ÿæˆçš„SWCCæ›²çº¿è¿›è¡Œvan Genuchtenæ¨¡å‹æ‹Ÿåˆ",
                                            key="enable_vg_fitting")

            curve_points = st.slider(
                "æ›²çº¿ç‚¹æ•°",
                min_value=20,
                max_value=200,
                value=100,
                help="SWCCæ›²çº¿ä¸Šçš„ç‚¹æ•°",
                key="curve_points"
            )

            min_suction = st.number_input(
                "æœ€å°å¸åŠ› (kPa)",
                min_value=0.001,
                max_value=1000.0,
                value=0.01,
                step=0.01,
                format="%.3f",
                help="SWCCæ›²çº¿çš„æœ€å°å¸åŠ›å€¼",
                key="min_suction"
            )

            max_suction = st.number_input(
                "æœ€å¤§å¸åŠ› (kPa)",
                min_value=100.0,
                max_value=10000000.0,  # å¢åŠ æœ€å¤§å€¼èŒƒå›´
                value=284804.0,
                step=100.0,
                help="SWCCæ›²çº¿çš„æœ€å¤§å¸åŠ›å€¼",
                key="max_suction"
            )

            # æ£€æŸ¥max_suctionæ˜¯å¦å¤§äºmin_suction
            if max_suction <= min_suction:
                st.warning("æœ€å¤§å¸åŠ›å¿…é¡»å¤§äºæœ€å°å¸åŠ›ï¼Œå·²è‡ªåŠ¨è°ƒæ•´")
                max_suction = min_suction * 100
                st.session_state['max_suction'] = max_suction

        else:
            # æ‰¹é‡é¢„æµ‹æ—¶çš„è®¾ç½®
            st.markdown("### ğŸ“Š æ‰¹é‡é¢„æµ‹è®¾ç½®")
            st.info("ä¸Šä¼ åŒ…å«å¤šç»„å‚æ•°çš„æ–‡ä»¶è¿›è¡Œæ‰¹é‡é¢„æµ‹")

    # ä¸»å†…å®¹åŒºåŸŸ
    st.markdown(f"""
    <div class="info-box">
    <strong>ğŸ“– å½“å‰æ¨¡å¼:</strong> {prediction_mode}<br>
    <strong>ğŸ¤– å½“å‰æ¨¡å‹:</strong> {selected_model}<br>
    <strong>ğŸ”¬ ç³»ç»Ÿç®€ä»‹:</strong> æœ¬ç³»ç»ŸåŸºäºXGBoostæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œé¢„æµ‹ç”Ÿç‰©ç‚­æ”¹æ€§åœŸçš„ä½“ç§¯å«æ°´ç‡ã€‚
    </div>
    """, unsafe_allow_html=True)

    # æ ¹æ®é¢„æµ‹æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„ç•Œé¢
    if prediction_mode == "å•ç‚¹é¢„æµ‹":
        # å•ç‚¹é¢„æµ‹ç•Œé¢
        display_single_prediction_interface(models, model_type, model_info, feature_info)
    else:
        # æ‰¹é‡é¢„æµ‹ç•Œé¢
        display_batch_prediction_interface(models, model_type, model_info, feature_info)


def display_single_prediction_interface(models, model_type, model_info, feature_info):
    """æ˜¾ç¤ºå•ç‚¹é¢„æµ‹ç•Œé¢"""
    # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æ˜¾ç¤ºä¸åŒçš„è¾“å…¥ç•Œé¢
    if model_type == 'group1':
        # å˜é‡ç»„ä¸€è¾“å…¥ç•Œé¢
        st.markdown('<div class="sub-header">ğŸ”¬ è¾“å…¥å‚æ•° - å˜é‡ç»„ä¸€</div>', unsafe_allow_html=True)

        # è·å–ç‰¹å¾ä¿¡æ¯
        feature_order = model_info.get('feature_order', [])
        biochar_categories = model_info.get('biochar_categories',
                                            ["å†œä¸šåºŸå¼ƒç‰©", "æ—ä¸šæ®‹ä½™ç‰©", "ç•œç¦½ç²ªä¾¿", "åŸå¸‚æ±¡æ³¥", "å…¶ä»–"])

        # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("### ğŸ’§ å¸åŠ›ä¸åœŸä½“å‚æ•°")

            # å¸åŠ›å‚æ•° - æ‰‹åŠ¨è¾“å…¥ä»»æ„å€¼
            suction = st.number_input(
                "åŸºè´¨å¸åŠ› (kPa)",
                min_value=0.001,
                max_value=1000000.0,
                value=100.0,
                step=1.0,
                format="%.3f",
                help="è¾“å…¥åŸºè´¨å¸åŠ›å€¼ï¼Œå•ä½kPaï¼ˆå¯ä»¥æ˜¯ä»»æ„å€¼ï¼‰",
                key="suction_input"
            )

            st.divider()

            # åœŸå£¤é¢—ç²’ç»„æˆ - æ‰‹åŠ¨è¾“å…¥
            st.markdown("**åœŸå£¤é¢—ç²’ç»„æˆï¼ˆå°æ•°å½¢å¼ï¼‰**")

            clay = st.number_input(
                "é»ç²’å«é‡ (clay)",
                min_value=0.0,
                max_value=1.0,
                value=0.2,
                step=0.01,
                format="%.3f",
                help="é»ç²’å«é‡ï¼ŒèŒƒå›´0-1ï¼Œå¦‚0.2è¡¨ç¤º20%",
                key="clay_input"
            )

            silt = st.number_input(
                "ç²‰ç²’å«é‡ (silt)",
                min_value=0.0,
                max_value=1.0,
                value=0.25,
                step=0.01,
                format="%.3f",
                help="ç²‰ç²’å«é‡ï¼ŒèŒƒå›´0-1ï¼Œå¦‚0.25è¡¨ç¤º25%",
                key="silt_input"
            )

            sand = st.number_input(
                "ç ‚ç²’å«é‡ (sand)",
                min_value=0.0,
                max_value=1.0,
                value=0.55,
                step=0.01,
                format="%.3f",
                help="ç ‚ç²’å«é‡ï¼ŒèŒƒå›´0-1ï¼Œå¦‚0.55è¡¨ç¤º55%",
                key="sand_input"
            )

            # æ˜¾ç¤ºé¢—ç²’ç»„æˆä¹‹å’Œ
            total_particles = clay + silt + sand
            if abs(total_particles - 1.0) > 0.01:
                st.warning(f"é¢—ç²’ç»„æˆä¹‹å’Œ: {total_particles:.3f} (å»ºè®®æ¥è¿‘1.0)")
            else:
                st.success(f"é¢—ç²’ç»„æˆä¹‹å’Œ: {total_particles:.3f}")

        with col2:
            st.markdown("### ğŸŒ¿ åœŸä½“ä¸ç”Ÿç‰©ç‚­åŸºæœ¬å‚æ•°")

            # å¹²å¯†åº¦ - æ‰‹åŠ¨è¾“å…¥
            dd = st.number_input(
                "å¹²å¯†åº¦ (dd, g/cmÂ³)",
                min_value=0.5,
                max_value=2.5,
                value=1.45,
                step=0.01,
                format="%.2f",
                help="åœŸä½“å¹²å¯†åº¦ï¼Œå•ä½ï¼šg/cmÂ³",
                key="dd_input"
            )

            st.divider()

            # ç”Ÿç‰©ç‚­æºé‡ - æ‰‹åŠ¨è¾“å…¥
            bc_percent = st.number_input(
                "ç”Ÿç‰©ç‚­æºé‡ (BC, %)",
                min_value=0.0,
                max_value=50.0,
                value=5.0,
                step=0.1,
                format="%.1f",
                help="ç”Ÿç‰©ç‚­æºé‡ï¼Œå•ä½ï¼š%",
                key="bc_percent_input"
            )

            # è½¬æ¢ä¸ºå°æ•°å½¢å¼
            bc = bc_percent / 100.0

            st.divider()

            # çƒ­è§£æ¸©åº¦ - æ ¹æ®BCå€¼åŠ¨æ€è°ƒæ•´
            if bc == 0:
                # å½“BC=0æ—¶ï¼Œçƒ­è§£æ¸©åº¦ä¸å­˜åœ¨
                st.markdown('<div class="warning-box">âš ï¸ ç”Ÿç‰©ç‚­æºé‡ä¸º0ï¼Œçƒ­è§£æ¸©åº¦ä¸å­˜åœ¨</div>', unsafe_allow_html=True)
                temperature = 0.0
            else:
                temperature = st.number_input(
                    "çƒ­è§£æ¸©åº¦ (temperature, Â°C)",
                    min_value=200.0,
                    max_value=900.0,
                    value=500.0,
                    step=10.0,
                    format="%.0f",
                    help="ç”Ÿç‰©ç‚­çƒ­è§£æ¸©åº¦ï¼Œå•ä½ï¼šÂ°C",
                    key="temperature_input"
                )

        with col3:
            st.markdown("### ğŸ§ª ç”Ÿç‰©ç‚­ç±»å‹å‚æ•°")

            # ç”Ÿç‰©ç‚­ç±»å‹é€‰æ‹© - æ ¹æ®BCå€¼åŠ¨æ€è°ƒæ•´
            if bc == 0:
                # å½“BC=0æ—¶ï¼Œç”Ÿç‰©ç‚­ç±»å‹ä¸å­˜åœ¨
                st.markdown('<div class="warning-box">âš ï¸ ç”Ÿç‰©ç‚­æºé‡ä¸º0ï¼Œç”Ÿç‰©ç‚­ç±»å‹ä¸å­˜åœ¨</div>', unsafe_allow_html=True)
                biochar_type = "å†œä¸šåºŸå¼ƒç‰©"  # é»˜è®¤å€¼ï¼Œä½†ä¸ä¼šå½±å“é¢„æµ‹
            else:
                biochar_type = st.selectbox(
                    "ç”Ÿç‰©ç‚­ç±»å‹ (Biochar_type_combined)",
                    options=biochar_categories,
                    index=0,
                    help="é€‰æ‹©ç”Ÿç‰©ç‚­çš„åŸææ–™ç±»å‹",
                    key="biochar_type_input"
                )

            st.divider()

            # å‚æ•°æ±‡æ€»å¡ç‰‡
            st.markdown("### ğŸ“‹ å½“å‰å‚æ•°æ¦‚è§ˆ")

            param_summary = pd.DataFrame({
                'å‚æ•°': ['å¸åŠ›', 'é»ç²’', 'ç²‰ç²’', 'ç ‚ç²’', 'å¹²å¯†åº¦', 'BCæºé‡', 'çƒ­è§£æ¸©åº¦', 'ç”Ÿç‰©ç‚­ç±»å‹'],
                'å€¼': [
                    f"{suction:.3f} kPa",
                    f"{clay:.3f}",
                    f"{silt:.3f}",
                    f"{sand:.3f}",
                    f"{dd:.2f} g/cmÂ³",
                    f"{bc_percent:.1f}%",
                    f"{temperature:.0f}Â°C",
                    biochar_type
                ]
            })

            st.dataframe(param_summary, use_container_width=True, hide_index=True)

    else:
        # å˜é‡ç»„äºŒè¾“å…¥ç•Œé¢
        st.markdown('<div class="sub-header">ğŸ”¬ è¾“å…¥å‚æ•° - å˜é‡ç»„äºŒ</div>', unsafe_allow_html=True)

        # è·å–ç‰¹å¾ä¿¡æ¯
        feature_order = model_info.get('feature_order', [])

        # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("### ğŸ’§ å¸åŠ›ä¸åœŸä½“å‚æ•°")

            # å¸åŠ›å‚æ•° - æ‰‹åŠ¨è¾“å…¥ä»»æ„å€¼
            suction = st.number_input(
                "åŸºè´¨å¸åŠ› (kPa)",
                min_value=0.001,
                max_value=1000000.0,
                value=100.0,
                step=1.0,
                format="%.3f",
                help="è¾“å…¥åŸºè´¨å¸åŠ›å€¼ï¼Œå•ä½kPaï¼ˆå¯ä»¥æ˜¯ä»»æ„å€¼ï¼‰",
                key="suction_input_group2"
            )

            st.divider()

            # åœŸå£¤é¢—ç²’ç»„æˆ - æ‰‹åŠ¨è¾“å…¥
            st.markdown("**åœŸå£¤é¢—ç²’ç»„æˆï¼ˆå°æ•°å½¢å¼ï¼‰**")

            clay = st.number_input(
                "é»ç²’å«é‡ (clay)",
                min_value=0.0,
                max_value=1.0,
                value=0.2,
                step=0.01,
                format="%.3f",
                help="é»ç²’å«é‡ï¼ŒèŒƒå›´0-1ï¼Œå¦‚0.2è¡¨ç¤º20%",
                key="clay_input_group2"
            )

            silt = st.number_input(
                "ç²‰ç²’å«é‡ (silt)",
                min_value=0.0,
                max_value=1.0,
                value=0.25,
                step=0.01,
                format="%.3f",
                help="ç²‰ç²’å«é‡ï¼ŒèŒƒå›´0-1ï¼Œå¦‚0.25è¡¨ç¤º25%",
                key="silt_input_group2"
            )

            sand = st.number_input(
                "ç ‚ç²’å«é‡ (sand)",
                min_value=0.0,
                max_value=1.0,
                value=0.55,
                step=0.01,
                format="%.3f",
                help="ç ‚ç²’å«é‡ï¼ŒèŒƒå›´0-1ï¼Œå¦‚0.55è¡¨ç¤º55%",
                key="sand_input_group2"
            )

            # æ˜¾ç¤ºé¢—ç²’ç»„æˆä¹‹å’Œ
            total_particles = clay + silt + sand
            if abs(total_particles - 1.0) > 0.01:
                st.warning(f"é¢—ç²’ç»„æˆä¹‹å’Œ: {total_particles:.3f} (å»ºè®®æ¥è¿‘1.0)")
            else:
                st.success(f"é¢—ç²’ç»„æˆä¹‹å’Œ: {total_particles:.3f}")

        with col2:
            st.markdown("### ğŸŒ¿ åœŸä½“ä¸ç”Ÿç‰©ç‚­åŸºæœ¬å‚æ•°")

            # å¹²å¯†åº¦ - æ‰‹åŠ¨è¾“å…¥
            dd = st.number_input(
                "å¹²å¯†åº¦ (dd, g/cmÂ³)",
                min_value=0.5,
                max_value=2.5,
                value=1.45,
                step=0.01,
                format="%.2f",
                help="åœŸä½“å¹²å¯†åº¦ï¼Œå•ä½ï¼šg/cmÂ³",
                key="dd_input_group2"
            )

            st.divider()

            # ç”Ÿç‰©ç‚­æºé‡ - æ‰‹åŠ¨è¾“å…¥
            bc_percent = st.number_input(
                "ç”Ÿç‰©ç‚­æºé‡ (BC, %)",
                min_value=0.0,
                max_value=50.0,
                value=5.0,
                step=0.1,
                format="%.1f",
                help="ç”Ÿç‰©ç‚­æºé‡ï¼Œå•ä½ï¼š%",
                key="bc_percent_input_group2"
            )

            # è½¬æ¢ä¸ºå°æ•°å½¢å¼
            bc = bc_percent / 100.0

            st.divider()

            # pHå€¼ - æ ¹æ®BCå€¼åŠ¨æ€è°ƒæ•´
            if bc == 0:
                # å½“BC=0æ—¶ï¼ŒpHä¸º0
                st.markdown('<div class="warning-box">âš ï¸ ç”Ÿç‰©ç‚­æºé‡ä¸º0ï¼ŒpHå€¼ä¸º0</div>', unsafe_allow_html=True)
                ph = 0.0
            else:
                ph = st.number_input(
                    "pHå€¼ (pH)",
                    min_value=0.0,
                    max_value=14.0,
                    value=8.0,
                    step=0.1,
                    format="%.1f",
                    help="ç”Ÿç‰©ç‚­pHå€¼",
                    key="ph_input"
                )

        with col3:
            st.markdown("### ğŸ§ª ç”Ÿç‰©ç‚­ç†åŒ–å‚æ•°")

            # æ ¹æ®BCå€¼åŠ¨æ€è°ƒæ•´
            if bc == 0:
                st.markdown('<div class="warning-box">âš ï¸ ç”Ÿç‰©ç‚­æºé‡ä¸º0ï¼Œä»¥ä¸‹å‚æ•°è‡ªåŠ¨è®¾ä¸º0</div>', unsafe_allow_html=True)
                at = 0.0
                ct = 0.0
            else:
                # ç°åˆ†å«é‡ï¼ˆç™¾åˆ†æ•°å½¢å¼ï¼‰- æ‰‹åŠ¨è¾“å…¥
                at = st.number_input(
                    "ç°åˆ†å«é‡ (AT, %)",
                    min_value=0.0,
                    max_value=100.0,
                    value=25.0,
                    step=0.1,
                    format="%.1f",
                    help="ç”Ÿç‰©ç‚­ç°åˆ†å«é‡ï¼Œå•ä½ï¼š%",
                    key="at_input"
                )

                # ç¢³å«é‡ï¼ˆç™¾åˆ†æ•°å½¢å¼ï¼‰- æ‰‹åŠ¨è¾“å…¥
                ct = st.number_input(
                    "ç¢³å«é‡ (CT, %)",
                    min_value=0.0,
                    max_value=100.0,
                    value=60.0,
                    step=0.1,
                    format="%.1f",
                    help="ç”Ÿç‰©ç‚­ç¢³å«é‡ï¼Œå•ä½ï¼š%",
                    key="ct_input"
                )

            st.divider()

            # å‚æ•°æ±‡æ€»å¡ç‰‡
            st.markdown("### ğŸ“‹ å½“å‰å‚æ•°æ¦‚è§ˆ")

            param_summary = pd.DataFrame({
                'å‚æ•°': ['å¸åŠ›', 'é»ç²’', 'ç²‰ç²’', 'ç ‚ç²’', 'å¹²å¯†åº¦', 'BCæºé‡', 'pH', 'AT', 'CT'],
                'å€¼': [
                    f"{suction:.3f} kPa",
                    f"{clay:.3f}",
                    f"{silt:.3f}",
                    f"{sand:.3f}",
                    f"{dd:.2f} g/cmÂ³",
                    f"{bc_percent:.1f}%",
                    f"{ph:.1f}",
                    f"{at:.1f}%",
                    f"{ct:.1f}%"
                ]
            })

            st.dataframe(param_summary, use_container_width=True, hide_index=True)

    # é¡µé¢åº•éƒ¨çš„é¢„æµ‹æŒ‰é’®
    st.divider()

    # é¢„æµ‹æŒ‰é’®å®¹å™¨
    predict_container = st.container()
    with predict_container:
        col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])

        with col_btn2:
            if st.button("ğŸš€ å¼€å§‹å•ç‚¹é¢„æµ‹", type="primary", use_container_width=True):
                # è°ƒç”¨å•ç‚¹é¢„æµ‹å‡½æ•°
                single_point_prediction(models, model_type, model_info, feature_info, locals())


def display_batch_prediction_interface(models, model_type, model_info, feature_info):
    """æ˜¾ç¤ºæ‰¹é‡é¢„æµ‹ç•Œé¢"""
    st.markdown('<div class="sub-header">ğŸ“Š æ‰¹é‡é¢„æµ‹</div>', unsafe_allow_html=True)

    # æ˜¾ç¤ºæ•°æ®æ ¼å¼è¦æ±‚
    st.markdown("""
    <div class="info-box">
    <strong>ğŸ“‹ æ•°æ®æ ¼å¼è¦æ±‚ï¼š</strong>
    1. ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶ï¼ŒåŒ…å«å¤šç»„å‚æ•°
    2. æ–‡ä»¶å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼ˆæ ¹æ®æ‰€é€‰æ¨¡å‹ï¼‰ï¼š
    """, unsafe_allow_html=True)

    if model_type == 'group1':
        st.markdown("""
        - **å˜é‡ç»„ä¸€å¿…éœ€åˆ—ï¼š** suction, clay, silt, sand, dd, BC, temperature, Biochar_type_combined
        - **æ³¨æ„äº‹é¡¹ï¼š** BCåˆ—ä¸ºç™¾åˆ†æ•°ï¼ˆå¦‚5è¡¨ç¤º5%ï¼‰ï¼ŒBiochar_type_combinedä¸ºç”Ÿç‰©ç‚­ç±»å‹
        - **ç”Ÿç‰©ç‚­ç±»å‹é€‰é¡¹ï¼š** å†œä¸šåºŸå¼ƒç‰©, æ—ä¸šæ®‹ä½™ç‰©, ç•œç¦½ç²ªä¾¿, åŸå¸‚æ±¡æ³¥, å…¶ä»–
        """)
    else:
        st.markdown("""
        - **å˜é‡ç»„äºŒå¿…éœ€åˆ—ï¼š** suction, clay, silt, sand, dd, BC, pH, AT, CT
        - **æ³¨æ„äº‹é¡¹ï¼š** BCåˆ—ä¸ºç™¾åˆ†æ•°ï¼ˆå¦‚5è¡¨ç¤º5%ï¼‰ï¼ŒATå’ŒCTä¸ºç™¾åˆ†æ•°ï¼ˆå¦‚25è¡¨ç¤º25%ï¼‰
        - **çº¦æŸæ¡ä»¶ï¼š** å½“BC=0æ—¶ï¼ŒpHã€ATã€CTè‡ªåŠ¨è®¾ä¸º0
        """)

    st.markdown("""
    <div class="warning-box">
    <strong>âš ï¸ é‡è¦æç¤ºï¼š</strong>
    1. ç¡®ä¿æ–‡ä»¶ç¼–ç ä¸ºUTF-8
    2. åœŸå£¤é¢—ç²’ç»„æˆ(clay, silt, sand)ä¹‹å’Œåº”åœ¨0-1èŒƒå›´å†…
    3. å»ºè®®å…ˆä¸‹è½½æ¨¡æ¿æ–‡ä»¶è¿›è¡Œæ•°æ®å‡†å¤‡
    </div>
    """, unsafe_allow_html=True)

    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([2, 1])

    with col1:
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ•°æ®æ–‡ä»¶ (CSVæˆ–Excel)",
            type=['csv', 'xlsx', 'xls'],
            help="é€‰æ‹©åŒ…å«æ‰¹é‡é¢„æµ‹æ•°æ®çš„æ–‡ä»¶",
            key="batch_file_uploader"
        )

    with col2:
        # ä¸‹è½½æ¨¡æ¿æ–‡ä»¶
        st.markdown("### ğŸ“¥ ä¸‹è½½æ¨¡æ¿")
        if model_type == 'group1':
            # åˆ›å»ºå˜é‡ç»„ä¸€æ¨¡æ¿
            template_data = {
                'suction': [100.0, 1000.0, 10000.0],
                'clay': [0.2, 0.3, 0.1],
                'silt': [0.25, 0.3, 0.2],
                'sand': [0.55, 0.4, 0.7],
                'dd': [1.45, 1.5, 1.4],
                'BC': [5.0, 10.0, 0.0],  # ç™¾åˆ†æ•°
                'temperature': [500, 600, 0],
                'Biochar_type_combined': ['å†œä¸šåºŸå¼ƒç‰©', 'æ—ä¸šæ®‹ä½™ç‰©', 'å†œä¸šåºŸå¼ƒç‰©']
            }
            template_df = pd.DataFrame(template_data)
            csv = template_df.to_csv(index=False).encode('utf-8')

            st.download_button(
                label="ä¸‹è½½å˜é‡ç»„ä¸€æ¨¡æ¿",
                data=csv,
                file_name="template_group1.csv",
                mime="text/csv",
                use_container_width=True,
                key="download_template_group1"
            )
        else:
            # åˆ›å»ºå˜é‡ç»„äºŒæ¨¡æ¿
            template_data = {
                'suction': [100.0, 1000.0, 10000.0],
                'clay': [0.2, 0.3, 0.1],
                'silt': [0.25, 0.3, 0.2],
                'sand': [0.55, 0.4, 0.7],
                'dd': [1.45, 1.5, 1.4],
                'BC': [5.0, 10.0, 0.0],  # ç™¾åˆ†æ•°
                'pH': [8.0, 7.5, 0.0],
                'AT': [25.0, 30.0, 0.0],  # ç™¾åˆ†æ•°
                'CT': [60.0, 65.0, 0.0]  # ç™¾åˆ†æ•°
            }
            template_df = pd.DataFrame(template_data)
            csv = template_df.to_csv(index=False).encode('utf-8')

            st.download_button(
                label="ä¸‹è½½å˜é‡ç»„äºŒæ¨¡æ¿",
                data=csv,
                file_name="template_group2.csv",
                mime="text/csv",
                use_container_width=True,
                key="download_template_group2"
            )

    # å¦‚æœæœ‰æ–‡ä»¶ä¸Šä¼ ï¼Œæ˜¾ç¤ºé¢„è§ˆå’Œè¿›è¡Œé¢„æµ‹
    if uploaded_file is not None:
        try:
            # è¯»å–æ–‡ä»¶
            if uploaded_file.name.endswith('.csv'):
                data_df = pd.read_csv(uploaded_file)
            else:
                data_df = pd.read_excel(uploaded_file)

            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            st.markdown("### ğŸ“‹ æ•°æ®é¢„è§ˆ")
            st.write(f"æ–‡ä»¶: {uploaded_file.name}")
            st.write(f"æ•°æ®è¡Œæ•°: {len(data_df)}")
            st.write(f"æ•°æ®åˆ—æ•°: {len(data_df.columns)}")

            # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
            with st.expander("æŸ¥çœ‹æ•°æ®è¯¦æƒ…"):
                st.dataframe(data_df.head(10))

            # éªŒè¯æ•°æ®
            st.markdown("### ğŸ” æ•°æ®éªŒè¯")
            validation_errors = validate_batch_data(data_df, model_type, feature_info)

            if validation_errors:
                st.error("âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼š")
                for error in validation_errors:
                    st.error(f"  - {error}")
                return
            else:
                st.success("âœ… æ•°æ®éªŒè¯é€šè¿‡")

            # å¼€å§‹æ‰¹é‡é¢„æµ‹
            st.markdown("### ğŸš€ å¼€å§‹æ‰¹é‡é¢„æµ‹")
            if st.button("å¼€å§‹æ‰¹é‡é¢„æµ‹", type="primary", use_container_width=True, key="batch_predict_button"):
                with st.spinner("æ­£åœ¨è¿›è¡Œæ‰¹é‡é¢„æµ‹..."):
                    model = models[model_type]

                    # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©é¢„æµ‹å‡½æ•°
                    if model_type == 'group1':
                        predictions = batch_predict_group1(model, data_df, feature_info)
                    else:
                        predictions = batch_predict_group2(model, data_df, feature_info)

                    # æ·»åŠ é¢„æµ‹ç»“æœåˆ°æ•°æ®æ¡†
                    result_df = data_df.copy()
                    result_df['é¢„æµ‹ä½“ç§¯å«æ°´ç‡'] = predictions

                    # è®¡ç®—é¢„æµ‹æˆåŠŸç‡
                    success_rate = (1 - result_df['é¢„æµ‹ä½“ç§¯å«æ°´ç‡'].isna().sum() / len(result_df)) * 100

                    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                    st.markdown("### ğŸ“Š æ‰¹é‡é¢„æµ‹ç»“æœ")
                    st.success(f"âœ… æ‰¹é‡é¢„æµ‹å®Œæˆï¼é¢„æµ‹æˆåŠŸç‡: {success_rate:.1f}%")

                    # æ˜¾ç¤ºç»“æœç»Ÿè®¡
                    col_stat1, col_stat2, col_stat3 = st.columns(3)
                    with col_stat1:
                        st.metric("æ€»æ ·æœ¬æ•°", len(result_df))
                    with col_stat2:
                        st.metric("é¢„æµ‹æˆåŠŸæ•°", len(result_df) - result_df['é¢„æµ‹ä½“ç§¯å«æ°´ç‡'].isna().sum())
                    with col_stat3:
                        st.metric("é¢„æµ‹å¤±è´¥æ•°", result_df['é¢„æµ‹ä½“ç§¯å«æ°´ç‡'].isna().sum())

                    # æ˜¾ç¤ºç»“æœé¢„è§ˆ
                    st.markdown("#### ğŸ” é¢„æµ‹ç»“æœé¢„è§ˆ")
                    st.dataframe(result_df.head(10))

                    # ç»˜åˆ¶é¢„æµ‹ç»“æœåˆ†å¸ƒ
                    st.markdown("#### ğŸ“ˆ é¢„æµ‹ç»“æœåˆ†å¸ƒ")
                    fig, ax = plt.subplots(figsize=(10, 6))

                    # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡å­—ä½“
                    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'Microsoft YaHei']
                    plt.rcParams['axes.unicode_minus'] = False

                    # ç»˜åˆ¶ç›´æ–¹å›¾
                    valid_predictions = result_df['Prediction of volumetric moisture content'].dropna()
                    if len(valid_predictions) > 0:
                        ax.hist(valid_predictions, bins=20, alpha=0.7, color='steelblue', edgecolor='black')
                        ax.axvline(valid_predictions.mean(), color='red', linestyle='--', linewidth=2,
                                   label=f'mean value: {valid_predictions.mean():.3f}')
                        ax.axvline(valid_predictions.median(), color='green', linestyle='--', linewidth=2,
                                   label=f'median: {valid_predictions.median():.3f}')

                        ax.set_xlabel('Volumetric water content', fontsize=12)
                        ax.set_ylabel('frequency', fontsize=12)
                        ax.set_title('Distribution histogram of prediction results', fontsize=14, fontweight='bold')
                        ax.legend()
                        ax.grid(True, alpha=0.3)

                        st.pyplot(fig)

                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        col_stat4, col_stat5, col_stat6, col_stat7 = st.columns(4)
                        with col_stat4:
                            st.metric("å¹³å‡å€¼", f"{valid_predictions.mean():.4f}")
                        with col_stat5:
                            st.metric("ä¸­ä½æ•°", f"{valid_predictions.median():.4f}")
                        with col_stat6:
                            st.metric("æœ€å°å€¼", f"{valid_predictions.min():.4f}")
                        with col_stat7:
                            st.metric("æœ€å¤§å€¼", f"{valid_predictions.max():.4f}")

                    # æä¾›ç»“æœä¸‹è½½
                    st.markdown("#### ğŸ’¾ ä¸‹è½½é¢„æµ‹ç»“æœ")

                    # åˆ›å»ºä¸‹è½½æŒ‰é’®
                    csv_result = result_df.to_csv(index=False).encode('utf-8')
                    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')

                    col_dl1, col_dl2 = st.columns(2)
                    with col_dl1:
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½CSVæ ¼å¼",
                            data=csv_result,
                            file_name=f"batch_predictions_{model_type}_{timestamp}.csv",
                            mime="text/csv",
                            use_container_width=True,
                            key="download_csv_batch"
                        )

                    with col_dl2:
                        # è½¬æ¢ä¸ºExcelæ ¼å¼
                        excel_buffer = io.BytesIO()
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            result_df.to_excel(writer, index=False, sheet_name='prediction results')
                        excel_buffer.seek(0)

                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½Excelæ ¼å¼",
                            data=excel_buffer,
                            file_name=f"batch_predictions_{model_type}_{timestamp}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True,
                            key="download_excel_batch"
                        )

                    # æ˜¾ç¤ºé¢„æµ‹ç»“æœè¯¦æƒ…
                    with st.expander("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†é¢„æµ‹ç»“æœ"):
                        st.dataframe(result_df)

        except Exception as e:
            st.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            st.error("è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹æ˜¯å¦æ­£ç¡®")


def single_point_prediction(models, model_type, model_info, feature_info, local_vars):
    """æ‰§è¡Œå•ç‚¹é¢„æµ‹"""
    # ä»å±€éƒ¨å˜é‡è·å–è¾“å…¥å‚æ•°
    suction = local_vars.get('suction', 100.0)
    clay = local_vars.get('clay', 0.2)
    silt = local_vars.get('silt', 0.25)
    sand = local_vars.get('sand', 0.55)
    dd = local_vars.get('dd', 1.45)
    bc_percent = local_vars.get('bc_percent', 5.0)
    bc = bc_percent / 100.0

    # éªŒè¯è¾“å…¥
    total_particles = clay + silt + sand
    if total_particles > 1.0:
        st.error("âŒ é»ç²’ã€ç²‰ç²’ã€ç ‚ç²’å«é‡ä¹‹å’Œä¸èƒ½è¶…è¿‡1.0ï¼")
        return

    if model_type not in models:
        st.error(f"âŒ æ¨¡å‹ {model_type} æœªåŠ è½½æˆåŠŸ")
        return

    model = models[model_type]

    # æ ¹æ®æ¨¡å‹ç±»å‹å‡†å¤‡è¾“å…¥æ•°æ®
    if model_type == 'group1':
        # å˜é‡ç»„ä¸€ï¼šä½¿ç”¨åˆ†ç±»ç‰¹å¾
        biochar_categories = model_info.get('biochar_categories',
                                            ["å†œä¸šåºŸå¼ƒç‰©", "æ—ä¸šæ®‹ä½™ç‰©", "ç•œç¦½ç²ªä¾¿", "åŸå¸‚æ±¡æ³¥", "å…¶ä»–"])
        temperature = local_vars.get('temperature', 500.0)
        biochar_type = local_vars.get('biochar_type', "å†œä¸šåºŸå¼ƒç‰©")

        # å½“BC=0æ—¶ï¼Œçƒ­è§£æ¸©åº¦å’Œç”Ÿç‰©ç‚­ç±»å‹è®¾ä¸ºé»˜è®¤å€¼
        if bc == 0:
            temperature = 0.0
            biochar_type = "å†œä¸šåºŸå¼ƒç‰©"  # é»˜è®¤å€¼

        # åˆ›å»ºç‰¹å¾DataFrame - æŒ‰ç…§è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåº
        features_dict = {
            'suction': float(suction),
            'clay': float(clay),
            'silt': float(silt),
            'sand': float(sand),
            'dd': float(dd),
            'BC': float(bc),  # å°æ•°å½¢å¼
            'temperature': float(temperature),  # ä½¿ç”¨ temperature è€Œä¸æ˜¯ Temp
            'Biochar_type_combined': biochar_type  # åˆ†ç±»ç‰¹å¾
        }

        # åˆ›å»ºDataFrameï¼Œç¡®ä¿Biochar_type_combinedæ˜¯categoryç±»å‹
        features_df = pd.DataFrame([features_dict])

        # å°†Biochar_type_combinedè½¬æ¢ä¸ºcategoryç±»å‹
        features_df['Biochar_type_combined'] = pd.Categorical(
            features_df['Biochar_type_combined'],
            categories=biochar_categories
        )

        # æŒ‰ç…§ç‰¹å¾é¡ºåºé‡æ–°æ’åˆ—åˆ—
        feature_order = ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'temperature', 'Biochar_type_combined']
        features_df = features_df[feature_order]

        # ä¿å­˜è¾“å…¥æ•°æ®ç”¨äºæ˜¾ç¤º
        input_data = {
            'suction': float(suction),
            'clay': float(clay),
            'silt': float(silt),
            'sand': float(sand),
            'dd': float(dd),
            'BC': float(bc),
            'temperature': float(temperature),
            'Biochar_type_combined': biochar_type
        }

    else:
        # å˜é‡ç»„äºŒï¼šç›´æ¥ä½¿ç”¨åŸå§‹å€¼
        ph = local_vars.get('ph', 8.0)
        at = local_vars.get('at', 25.0)
        ct = local_vars.get('ct', 60.0)

        if bc == 0:
            # ç¡®ä¿å½“BC=0æ—¶ï¼ŒATã€CTã€pHä¸º0
            ph = 0.0
            at = 0.0
            ct = 0.0

        # åˆ›å»ºç‰¹å¾DataFrame
        feature_order = ['suction', 'clay', 'silt', 'sand', 'dd', 'BC', 'pH', 'AT', 'CT']

        features = [
            float(suction),
            float(clay),
            float(silt),
            float(sand),
            float(dd),
            float(bc),  # å°æ•°å½¢å¼
            float(ph),
            float(at),  # ç™¾åˆ†æ•°å½¢å¼
            float(ct)  # ç™¾åˆ†æ•°å½¢å¼
        ]

        features_df = pd.DataFrame([features], columns=feature_order)

        # ä¿å­˜è¾“å…¥æ•°æ®ç”¨äºæ˜¾ç¤º
        input_data = {
            'suction': float(suction),
            'clay': float(clay),
            'silt': float(silt),
            'sand': float(sand),
            'dd': float(dd),
            'BC': float(bc),
            'pH': float(ph),
            'AT': float(at),
            'CT': float(ct)
        }

    # è¿›è¡Œé¢„æµ‹
    with st.spinner("æ­£åœ¨è¿›è¡Œé¢„æµ‹è®¡ç®—..."):
        try:
            # æ˜¾ç¤ºè¾“å…¥ç‰¹å¾ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            with st.expander("ğŸ” æŸ¥çœ‹è¾“å…¥ç‰¹å¾å€¼"):
                st.write(f"æ¨¡å‹ç±»å‹: {model_type}")
                st.write("è¾“å…¥ç‰¹å¾å€¼:")
                st.dataframe(features_df)

                # å¦‚æœæ¨¡å‹æœ‰feature_names_in_å±æ€§ï¼Œæ˜¾ç¤ºæ¨¡å‹æœŸæœ›çš„ç‰¹å¾
                if hasattr(model, 'feature_names_in_'):
                    st.write("æ¨¡å‹æœŸæœ›çš„ç‰¹å¾:", list(model.feature_names_in_))
                    st.write("è¾“å…¥çš„ç‰¹å¾:", list(features_df.columns))

            # è¿›è¡Œé¢„æµ‹
            prediction = model.predict(features_df)[0]

            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            st.markdown('<div class="sub-header">ğŸ“Š é¢„æµ‹ç»“æœ</div>', unsafe_allow_html=True)

            # åˆ›å»ºç»“æœå±•ç¤ºåŒºåŸŸ
            col_a, col_b = st.columns([2, 1])

            with col_a:
                st.markdown(f"""
                <div class="success-box" style="text-align: center;">
                    <h2 style="margin: 0;">é¢„æµ‹ä½“ç§¯å«æ°´ç‡</h2>
                    <h1 style="color: #2E8B57; font-size: 3rem; margin: 10px 0;">{prediction:.4f}</h1>
                    <p>å•ä½ä½“ç§¯åœŸå£¤ä¸­æ°´çš„ä½“ç§¯</p>
                </div>
                """, unsafe_allow_html=True)

                # è¾…åŠ©æŒ‡æ ‡
                col_a1, col_a2 = st.columns(2)

                with col_a1:
                    # è®¡ç®—é¥±å’Œåº¦ï¼ˆå‡è®¾å­”éš™ç‡ä¸º0.4ï¼‰
                    porosity = 0.4
                    saturation = (prediction / porosity) * 100 if porosity > 0 else 0
                    st.metric("ä¼°ç®—é¥±å’Œåº¦", f"{saturation:.1f}%")

                with col_a2:
                    # æä¾›å®šæ€§è¯„ä¼°
                    if prediction > 0.35:
                        assessment = "é«˜æŒæ°´èƒ½åŠ›"
                        color = "#32CD32"
                        emoji = "ğŸ”µ"
                    elif prediction > 0.2:
                        assessment = "ä¸­ç­‰æŒæ°´èƒ½åŠ›"
                        color = "#FFA500"
                        emoji = "ğŸŸ¡"
                    else:
                        assessment = "ä½æŒæ°´èƒ½åŠ›"
                        color = "#FF4500"
                        emoji = "ğŸ”´"

                    st.markdown(f"**è¯„ä¼°:** {emoji} <span style='color:{color};font-weight:bold'>{assessment}</span>",
                                unsafe_allow_html=True)

            with col_b:
                st.markdown("### ğŸ“‹ è¾“å…¥å‚æ•°è¯¦æƒ…")

                # æ˜¾ç¤ºè¾“å…¥å‚æ•°
                detail_data = []
                for key, value in input_data.items():
                    if key == 'BC':
                        display_value = f"{value * 100:.1f}%"
                        unit = "%"
                    elif key in ['AT', 'CT']:
                        display_value = f"{value:.1f}%"
                        unit = "%"
                    elif key in ['clay', 'silt', 'sand']:
                        display_value = f"{value:.3f}"
                        unit = "å°æ•°"
                    elif key == 'suction':
                        display_value = f"{value:.3f} kPa"
                        unit = "kPa"
                    elif key == 'dd':
                        display_value = f"{value:.2f} g/cmÂ³"
                        unit = "g/cmÂ³"
                    elif key == 'temperature':
                        display_value = f"{value:.0f}Â°C"
                        unit = "Â°C"
                    elif key == 'pH':
                        display_value = f"{value:.1f}"
                        unit = "-"
                    elif key == 'Biochar_type_combined':
                        display_value = str(value)
                        unit = "ç±»å‹"
                    else:
                        display_value = str(value)
                        unit = ""

                    detail_data.append({
                        'å‚æ•°': key,
                        'å€¼': display_value,
                        'å•ä½': unit
                    })

                detail_df = pd.DataFrame(detail_data)
                st.dataframe(detail_df, use_container_width=True, hide_index=True)

                # ä¸‹è½½æŒ‰é’®
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ",
                    data=detail_df.to_csv(index=False).encode('utf-8'),
                    file_name=f"SWCCé¢„æµ‹_{model_type}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True,
                    key="download_single_result"
                )

            # ä»session stateè·å–SWCCæ›²çº¿è®¾ç½®
            curve_points = st.session_state.get('curve_points', 100)
            min_suction = st.session_state.get('min_suction', 0.01)
            max_suction = st.session_state.get('max_suction', 284804.0)
            enable_vg_fitting = st.session_state.get('enable_vg_fitting', True)

            # æ£€æŸ¥max_suctionæ˜¯å¦å¤§äºmin_suction
            if max_suction <= min_suction:
                st.warning("æœ€å¤§å¸åŠ›å¿…é¡»å¤§äºæœ€å°å¸åŠ›ï¼Œå·²è‡ªåŠ¨è°ƒæ•´")
                max_suction = min_suction * 100
                st.session_state['max_suction'] = max_suction

            # ç”ŸæˆSWCCæ›²çº¿
            st.markdown('<div class="sub-header">ğŸ“ˆ SWCCæ›²çº¿</div>', unsafe_allow_html=True)

            # ç”Ÿæˆå¸åŠ›èŒƒå›´ï¼ˆå¯¹æ•°å‡åŒ€åˆ†å¸ƒï¼‰
            suction_range = np.logspace(np.log10(min_suction), np.log10(max_suction), curve_points)

            # ç”ŸæˆSWCCæ›²çº¿æ•°æ®
            with st.spinner("æ­£åœ¨ç”ŸæˆSWCCæ›²çº¿..."):
                predictions = generate_swcc_curve(model, model_type, input_data, suction_range)

                # VGæ¨¡å‹æ‹Ÿåˆ
                vg_params = None
                r_squared = 0
                fitted_curve = None

                if enable_vg_fitting:
                    with st.spinner("æ­£åœ¨è¿›è¡ŒVGæ¨¡å‹æ‹Ÿåˆ..."):
                        popt, pcov, r_squared, fitted_curve = fit_vg_model(suction_range, predictions)

                        if popt is not None:
                            vg_params = popt
                            st.success(f"âœ… VGæ¨¡å‹æ‹ŸåˆæˆåŠŸï¼RÂ² = {r_squared:.6f}")

                # ç»˜åˆ¶SWCCæ›²çº¿
                current_point = (suction, prediction) if suction >= min_suction and suction <= max_suction else None

                fig = plot_swcc_with_vg_fit(suction_range, predictions, vg_params, current_point)

                st.pyplot(fig)

                # æ˜¾ç¤ºVGæ¨¡å‹å‚æ•°
                if enable_vg_fitting and vg_params is not None:
                    display_vg_parameters(vg_params, r_squared, suction_range, predictions)

                # æä¾›æ›²çº¿æ•°æ®ä¸‹è½½
                curve_data = pd.DataFrame({
                    'Suction(kPa)': suction_range,
                    'Volumetric_Water_Content': predictions
                })

                # å¦‚æœæœ‰VGæ‹Ÿåˆç»“æœï¼Œæ·»åŠ åˆ°æ•°æ®ä¸­
                if fitted_curve is not None:
                    curve_data['VG_Fitted_Water_Content'] = fitted_curve
                    curve_data['Residual'] = predictions - fitted_curve

                csv_curve = curve_data.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½SWCCæ›²çº¿æ•°æ®",
                    data=csv_curve,
                    file_name=f"SWCCæ›²çº¿_{model_type}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True,
                    key="download_swcc_curve"
                )

        except Exception as e:
            st.error(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            st.error("è¯·æ£€æŸ¥ç‰¹å¾é¡ºåºæˆ–æ¨¡å‹æ–‡ä»¶")

            # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
            with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                import traceback
                st.code(traceback.format_exc())


if __name__ == "__main__":
    main()